Epoch	train_loss	val_loss
1	0.15359710704069585	0.7753195464611053
2	0.08178252000005967	0.9043135792016983
3	0.07608849533372214	0.6276195719838142
4	0.09302170329896466	0.5921805053949356
5	0.06754939928470305	1.093376487493515
6	0.06156776186091722	0.9083225578069687
7	0.05817160259182317	0.6886417679488659
8	0.060299911405208045	0.8765911906957626
9	0.04240466747069149	1.2345776706933975
10	0.06061419241578497	0.774795226752758
11	0.0839526440361927	1.1430508494377136
12	0.06412211408062124	0.7404605820775032
13	0.05485853737732045	0.8150943666696548
14	0.05177349580752114	0.8030803054571152
15	0.06427067257205905	1.2048510909080505
16	0.040560179388867926	0.8838628083467484
17	0.05382833076248938	1.3038124442100525
18	0.052003330467026966	0.6996198445558548
19	0.042110354669283104	0.7101583480834961
20	0.04312862874515607	0.8365527614951134
21	0.041336580020242764	1.2287455946207047
22	0.04097205860379863	0.8011079803109169
23	0.04284428861920889	0.9766781628131866
24	0.0629436186051222	0.8712983503937721
25	0.03844181289980497	0.7375590577721596
26	0.03354148054799882	0.8931006863713264
27	0.045445022275139815	0.9283208027482033
28	0.03896264395783183	0.9012743234634399
29	0.030792202535449346	0.9850102216005325
30	0.06959051491977604	0.7861863970756531
31	0.04340803641515675	1.3385939747095108
32	0.0383205912362596	0.7612193375825882
33	0.044503971290857355	0.6415458023548126
34	0.03175834525192958	1.0439795553684235
35	0.03568481183504622	0.8014279529452324
36	0.05747775106708854	1.608919471502304
37	0.05281841698044016	0.7775333747267723
38	0.07046170293219971	0.6181086450815201
39	0.05792068583484159	0.8425371497869492
40	0.03465296165367494	0.9468889981508255

Test predictions. 

pred	true
0.4643310308456421	1
0.3855079710483551	0
0.9736167788505554	1
0.41997233033180237	1
0.44891485571861267	0
0.4145447313785553	1
0.9028369784355164	1
0.3967738151550293	1
0.5224572420120239	0
0.2850635051727295	0
0.679008424282074	1
0.5122389793395996	1
0.3468446433544159	1
0.2080698311328888	0
0.12381532043218613	0
0.07741845399141312	0
0.10098758339881897	0
0.12023308128118515	0
0.569663941860199	0
0.8760325908660889	0
0.16822712123394012	1
0.669785737991333	1
0.22253334522247314	1
0.8968053460121155	0
0.03778272867202759	0
0.3244872987270355	1
0.4897063970565796	0
0.3074384033679962	1
0.4969715178012848	0
0.9535497426986694	1
0.3924538791179657	1
0.6617189645767212	0
0.4897063970565796	0
0.5865613222122192	0
0.1630866676568985	0
0.8009958863258362	0
0.20053113996982574	0
0.42208999395370483	0
0.05872379243373871	1

Accuracy: 0.5384615384615384
